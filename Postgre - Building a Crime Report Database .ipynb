{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Database for Crime Reports\n",
    "\n",
    "\n",
    "The goal of this project build a database for storing data related to crimes that occurred in Boston.\n",
    "\n",
    "\n",
    "The dataset is available in the file `Boston.csv` stored locally on my computer.\n",
    "\n",
    "\n",
    "### Column Definitions\n",
    "\n",
    "- **incident_number:** Represents the identifier of the crime\n",
    "- **offense_code:** Identifier code for the committed crime\n",
    "- **description:** Description of the crime\n",
    "- **date:** Date when the crime happened \n",
    "- **day_of_the_week:** Corresponding day of the week\n",
    "- **lat:** Location of the crime (latitude coordinates)\n",
    "- **long:** Location of the crime (longitude coordinates)\n",
    "\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "To get started, I recommend creating a database named `crimes_db` with a table – `boston_crimes` – using appropriate datatypes for storing the data from the `Boston.csv` file. The table will be created inside a schema named `crimes`. Additionally, create the `readonly` and `readwrite` groups with the appropriate privileges. Finally, create one user for each of these groups.\n",
    "\n",
    "### Summary of Results:\n",
    "I have been able to create a new database with it's own Schema. Database `crime_db` has two groups and 1 user in each group.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Crime Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Connecting to the main PostgreSQL database named \"dq\"\n",
    "conn = psycopg2.connect(dbname=\"dq\", user=\"dq\")\n",
    "conn.autocommit = True  # Set autocommit to True for immediate execution of SQL statements\n",
    "cur = conn.cursor()     # Create a cursor for executing SQL statements\n",
    "\n",
    "# Creating a new database named \"crime_db\"\n",
    "cur.execute(\"CREATE DATABASE crime_db;\")\n",
    "conn.autocommit = False  # Set autocommit to False for manual control over transactions\n",
    "\n",
    "# Connecting to the newly created \"crime_db\" database\n",
    "crime_db_conn = psycopg2.connect(dbname=\"crime_db\", user=\"dq\")\n",
    "crime_cur = crime_db_conn.cursor()  # Create a cursor for the \"crime_db\" database\n",
    "\n",
    "# Creating a schema named \"crimes\" within the \"crime_db\" database\n",
    "crime_cur.execute(\"CREATE SCHEMA crimes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining the Column Names and Sample\n",
    "\n",
    "Now we'll want to figure out the best datatype to use for our `crime_db` table.\n",
    "\n",
    "We'll start by reading the column names from the `boston.csv` file as well as the first row. This way, we will have them at hand throughout this project so we can easily refer to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header Row: ['incident_number', 'offense_code', 'description', 'date', 'day_of_the_week', 'lat', 'long']\n",
      "First Data Row: ['1', '619', 'LARCENY ALL OTHERS', '2018-09-02', 'Sunday', '42.35779134', '-71.13937053']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('boston.csv', 'r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    all_rows = list(csv_reader)\n",
    "    col_headers = all_rows[0]\n",
    "    first_row = all_rows[1]\n",
    "\n",
    "# Now, col_headers contains the header row, and first_row contains the first data row\n",
    "print(\"Header Row:\", col_headers)\n",
    "print(\"First Data Row:\", first_row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Best Datatype to use for columns in my crime_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check number of rows to get the max value. This will determine the Storage size to use for the ID column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298329\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('boston.csv')\n",
    "num_rows = len(df)\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use 8 bytes for storing the values from the `incident_number` column because it's larger that 2 bytes which range only from -32768 to 32767"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check For Max value in the `offense_code` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest value in index 1: 3831\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('boston.csv', header=None, skiprows=1)  # Assuming the header is not included in the CSV file\n",
    "\n",
    "# Slice away the header for the dataset\n",
    "\n",
    "# Convert values in index 1 to integers\n",
    "index_1_values = df.iloc[:, 1].astype(int)\n",
    "\n",
    "# Find the highest value in index 1\n",
    "highest_value = index_1_values.max()\n",
    "\n",
    "print(\"Highest value in index 1:\", highest_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use 2 bytes for storing this values in our `crime_db`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's find out the distinct value in `day_of_the_week` column, as this will help us know if will be using an Enum datatype. There are only 7days in a week!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 0: 298329 distinct values\n",
      "Column 1: 219 distinct values\n",
      "Column 2: 239 distinct values\n",
      "Column 3: 1177 distinct values\n",
      "Column 4: 7 distinct values\n",
      "Column 5: 18177 distinct values\n",
      "Column 6: 18177 distinct values\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def get_col_set(csv_filename, col_index):\n",
    "    column_values = set()\n",
    "\n",
    "    with open(csv_filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader, None)\n",
    "        for row in reader:\n",
    "            # Make sure the row has enough columns before trying to access col_index\n",
    "            if col_index < len(row):\n",
    "                column_values.add(row[col_index])\n",
    "\n",
    "    return column_values\n",
    "\n",
    "\n",
    "csv_filename = 'boston.csv'\n",
    "\n",
    "for col_index in range(7):\n",
    "    distinct_values = get_col_set(csv_filename, col_index)\n",
    "    num_distinct_values = len(distinct_values)\n",
    "    print(\"Column {}: {} distinct values\".format(col_index, num_distinct_values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns with a low number of distinct values tend to be good candidates for enumerated datatype, which will be date_of_the_week. So the an enumerated datatype is what we'll use to store date of the week in our `crime_db`table. And moreover, they can only be 7days in a week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the Precision of the lat and Long column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different Precisions:\n",
      "Precision 16: 1491\n",
      "Sample Values: ['42.27796370000001', '42.32960870000001', '42.29918970000001']\n",
      "Precision 17: 9648\n",
      "Sample Values: ['42.325694899999995', '42.347972399999996', '42.347972399999996']\n",
      "Precision 6: 23\n",
      "Sample Values: ['42.2812', '42.2812', '42.3349']\n",
      "Precision 7: 495\n",
      "Sample Values: ['42.37766', '42.37766', '42.28137']\n",
      "Precision 8: 4941\n",
      "Sample Values: ['42.351084', '42.351084', '42.351084']\n",
      "Precision 9: 17262\n",
      "Sample Values: ['42.3503876', '42.3218854', '42.3353997']\n",
      "Precision 10: 264469\n",
      "Sample Values: ['42.35779134', '42.30682138', '42.34658879']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('boston.csv')\n",
    "\n",
    "# Check the column with index 5 or 6\n",
    "column_index = 5\n",
    "column_name = df.columns[column_index]\n",
    "\n",
    "# Dictionary to store precision count for each element\n",
    "precision_counts = {}\n",
    "\n",
    "# Iterate through each element in the column\n",
    "for value in df[column_name]:\n",
    "    # Convert the value to string to handle decimal points\n",
    "    value_str = str(value)\n",
    "    # Find the position of the decimal point\n",
    "    decimal_index = value_str.find('.')\n",
    "    # Count the number of digits before and after the decimal point\n",
    "    if decimal_index == -1:\n",
    "        precision = len(value_str)\n",
    "    else:\n",
    "        precision = len(value_str[:decimal_index]) + len(value_str[decimal_index+1:])\n",
    "    # Update the precision count for this precision\n",
    "    if precision not in precision_counts:\n",
    "        precision_counts[precision] = [value_str]\n",
    "    else:\n",
    "        precision_counts[precision].append(value_str)\n",
    "\n",
    "# Print out precision counts\n",
    "print(\"Different Precisions:\")\n",
    "for precision, values in precision_counts.items():\n",
    "    print(\"Precision {}: {}\".format(precision, len(values)))\n",
    "    print(\"Sample Values:\", values[:3])  # Print out sample values for each precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use Decimal type for storing this. Precision will be 17 and scale will be 15 for both long and lat column in our `crime_db`\n",
    "\n",
    "**NOTE:** FOR Description and Date column, We'll use text and datetime type. Reason is that the values in description column have uncertain cizes and the datetime column already has the format that the datetime type support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Table & Loading Data into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Before that we'' create the Enum Type first\n",
    "\n",
    "crime_cur.execute(\"CREATE TYPE week_days AS ENUM ('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday');\")\n",
    "\n",
    "# Define the SQL statement to create the table\n",
    "create_table_sql = \"\"\"\n",
    "                   CREATE TABLE crimes.boston_crimes (\n",
    "                       incident_number  BIGINT,\n",
    "                       offense_code SMALLINT,\n",
    "                       description TEXT,\n",
    "                       date DATE,\n",
    "                       day_of_the_week week_days,\n",
    "                       lat DECIMAL(17, 15),\n",
    "                       long DECIMAL(17, 15)\n",
    "                   );\n",
    "                   \"\"\"\n",
    "\n",
    "crime_cur.execute(create_table_sql)\n",
    "\n",
    "#Load data into the `bostom_crimes` Table\n",
    "import csv\n",
    "with open(\"boston.csv\", \"r\") as f:\n",
    "    crime_cur.copy_expert(\"COPY crimes.boston_crimes FROM STDIN WITH CSV HEADER;\", f)\n",
    "\n",
    "# Revoking Public Privileges\n",
    "crime_cur.execute(\"REVOKE ALL ON SCHEMA public FROM public;\")\n",
    "crime_cur.execute(\"REVOKE ALL ON DATABASE crime_db FROM public;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Creating User Groups & Users\n",
    "\n",
    "We've made sure that we aren't going to inadvertently inherit privileges from the public group. The next step is to create our two user groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Created two groups named readonly and readwrite with NOLOGIN option\n",
    "crime_cur.execute(\"CREATE GROUP readonly NOLOGIN;\")\n",
    "crime_cur.execute(\"CREATE GROUP readwrite NOLOGIN;\")\n",
    "\n",
    "# Grant CONNECT to the crime_db to both groups\n",
    "crime_cur.execute(\"GRANT CONNECT ON DATABASE crime_db TO readonly;\")\n",
    "crime_cur.execute(\"GRANT CONNECT ON DATABASE crime_db TO readwrite;\")\n",
    "\n",
    "# Grant USAGE to the crimes schema to both groups\n",
    "crime_cur.execute(\"GRANT USAGE ON SCHEMA crimes TO readonly;\")\n",
    "crime_cur.execute(\"GRANT USAGE ON SCHEMA crimes TO readwrite;\")\n",
    "\n",
    "# Granted group-specific privileges to each group on all tables in the crimes schema\n",
    "# readonly group should only be granted the SELECT privilege\n",
    "crime_cur.execute(\"GRANT SELECT ON ALL TABLES IN SCHEMA crimes TO readonly;\")\n",
    "\n",
    "# readwrite group should be granted the SELECT, INSERT, DELETE, and UPDATE privileges\n",
    "crime_cur.execute(\"GRANT SELECT, INSERT, DELETE, UPDATE ON ALL TABLES IN SCHEMA crimes TO readwrite;\")\n",
    "\n",
    "# Create a user named data_analyst with password secret1\n",
    "crime_cur.execute(\"CREATE USER data_analyst WITH PASSWORD 'secret1';\")\n",
    "\n",
    "# Assign data_analyst user to the readonly group\n",
    "crime_cur.execute(\"GRANT readonly TO data_analyst;\")\n",
    "\n",
    "# Create a user named data_scientist with password secret2\n",
    "crime_cur.execute(\"CREATE USER data_scientist WITH PASSWORD 'secret2';\")\n",
    "\n",
    "# Assign data_scientist user to the readwrite group\n",
    "crime_cur.execute(\"GRANT readwrite TO data_scientist;\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
